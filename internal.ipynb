{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from utils.helper import Proxies\n",
    "\n",
    "proxies = Proxies(annoymous=False, from_env=True)\n",
    "# useragent = proxies.get_proxy_useragent()\n",
    "proxy_ip = proxies.get_proxy_ip()\n",
    "\n",
    "proxy = {\n",
    "    \"http\": proxy_ip,\n",
    "    \"https\": proxy_ip\n",
    "}\n",
    "# headers = {\"Connection\" : \"close\",  \"User-Agent\" : useragent}  \n",
    "# print(\"User Agent:\", useragent)\n",
    "# print(\"Proxy ip:\", proxy_ip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import traceback\n",
    "import time\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from datetime import datetime, timedelta, date\n",
    "from IPython.display import display\n",
    "\n",
    "class GoogleRSSFeedScraper():\n",
    "    def __init__(self, proxy=None):\n",
    "        self.proxy = proxy\n",
    "        self.state = {}\n",
    "        self.base_url = \"https://news.google.com/rss/search?\"\n",
    "    \n",
    "    def scrape(self, search_query, start_time=datetime.now().date(), end_time = datetime.now().date(), scrape_period = 7, add_url_parameters={}, save_state=False, save_result=False, save_folder=\"./data\", preview_result=True, sleep_interval=5):\n",
    "        \"\"\"\n",
    "        Web scrape google news rss feeds. \n",
    "        - Use date(YYYY, MM, DD) to initiate date arguments. eg: date(2025, 2, 19)\n",
    "        Args:\n",
    "            search_query (String): Search query\n",
    "            start_time (Date): Default to datetime.now(). \n",
    "            end_time (Date): Default to datetime.now(). \n",
    "            scrape_period (int): no. of days for each scrape instance (inclusive of start and end: must be more than 1)\n",
    "            add_url_parameters (dict): Additional url parameters\n",
    "            save_state (boolean): Save state progress in json file. format: f\"/scrape_state_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "            save_result (boolean): Save dataframe as pickle file. format: f\"/scrape_result_{datetime.now().strftime('%Y%m%d%H%M%S')}.pkl\"\n",
    "            save_folder (String): root folder to save state and result\n",
    "            preview_result (boolean): Show pandas dataframe after processing\n",
    "            sleep_interval (int): Sleep for 3 seconds for every X interations (intervals).\n",
    "        \"\"\"\n",
    "        if end_time < start_time:\n",
    "            raise ValueError(\"End time must be greater than start time!\")\n",
    "        elif scrape_period < 1:\n",
    "            raise ValueError(\"Scrape period must be more than 1!\")\n",
    "        \n",
    "        # Save state\n",
    "        self.state = {\n",
    "            \"parameters\": {\n",
    "                \"search_query\": search_query,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"scrape_period\": scrape_period,\n",
    "                \"add_url_parameters\": add_url_parameters\n",
    "            },\n",
    "            \"iter_no\": 0\n",
    "        }\n",
    "        to_time = None\n",
    "        df = pd.DataFrame()\n",
    "        try:\n",
    "            scrape_period -= 1\n",
    "            while start_time <= end_time:\n",
    "                to_time = min(start_time + timedelta(days=scrape_period), end_time)\n",
    "                # Format and encode URL\n",
    "                url_parameters = {\"q\": f\"{search_query} after:{start_time.strftime('%Y-%m-%d')} before:{to_time.strftime('%Y-%m-%d')}\", **add_url_parameters}\n",
    "                url = self.base_url + urllib.parse.urlencode(url_parameters)\n",
    "\n",
    "                self.state[\"to_time\"] = to_time\n",
    "                self.state[\"url\"] = url\n",
    "                \n",
    "                # GET request and parse\n",
    "                df_intermediate = self.fetch_and_parse(url, pandas= True)\n",
    "                if len(df_intermediate) > 0:\n",
    "                    df = pd.concat([df,df_intermediate])\n",
    "                    df.drop_duplicates(subset=[\"pubDate\", \"title\", \"source\"], inplace=True)\n",
    "                    df.sort_values(by='pubDate', inplace=True)\n",
    "                    df.reset_index(drop=True, inplace=True)\n",
    "  \n",
    "                self.state[\"iter_no\"] += 1\n",
    "                if self.state[\"iter_no\"] % sleep_interval == 0:\n",
    "                    print(f\"-- Current state: {start_time}-{to_time}, record_count: {len(df)}, iter: {self.state['iter_no']}\")\n",
    "                    time.sleep(3)\n",
    "                start_time += timedelta(days=scrape_period+1)  \n",
    "        except Exception as e:\n",
    "            print(f\"########## Error: {start_time}-{to_time} {end_time} #########\")\n",
    "            print(traceback.format_exc())\n",
    "        finally:\n",
    "            self.state[\"record_count\"] = len(df)\n",
    "            if preview_result:\n",
    "                print(f\"############## Result: {len(df)} records ##############\")\n",
    "                display(df.tail())\n",
    "            if save_state:\n",
    "                save_path = save_folder.rstrip(\"/\") + f\"/scrape_state_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "                self.state[\"save_state_path\"] = save_path\n",
    "                with open(save_path, \"w\") as f:\n",
    "                    json.dump(self.state, f, indent=4, default=str)\n",
    "                print(\"Saved state to:\", save_path)\n",
    "            if save_result and len(df) > 0:\n",
    "                save_path = save_folder.rstrip(\"/\") + f\"/scrape_result_{datetime.now().strftime('%Y%m%d%H%M%S')}.pkl\"\n",
    "                self.state[\"save_result_path\"] = save_path\n",
    "                df.to_pickle(save_path)\n",
    "                print(\"Saved pickle to:\", save_path)\n",
    "            \n",
    "\n",
    "    def fetch_and_parse(self, url, pandas= True):\n",
    "        response = requests.get(url, proxies=self.proxy) \n",
    "        soup = bs.BeautifulSoup(response.text,'xml')\n",
    "\n",
    "        result = []\n",
    "        for item in soup.find_all('item'):\n",
    "            result.append({\n",
    "                \"title\": item.title.text,\n",
    "                \"link\": item.link.text,\n",
    "                \"pubDate\": item.pubDate.text,\n",
    "                \"source\": item.source.text,\n",
    "                \"description\": item.description.text,\n",
    "            })\n",
    "        if pandas:\n",
    "            if len(result) == 0:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(result)\n",
    "            df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %Z', utc=True)\n",
    "            return df\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_feed_scraper = GoogleRSSFeedScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- UBS  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 1, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 1, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 1, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 1, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 1, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 2, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 2, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 2, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 3, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 3, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 4, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 4, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 4, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 4, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 4, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 4, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 4, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 4, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 4, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 4, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 4, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 8, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 9, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 12, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 14, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 14, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 14, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 16, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 17, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 19, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 23, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 24, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 27, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 30, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 35, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 41, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 45, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 45, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 51, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 59, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 64, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 71, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 79, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 81, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 88, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 101, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 112, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 126, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 133, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 139, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 158, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 169, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 189, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 207, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 227, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 289, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 363, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 428, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 516, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 609, iter: 305\n",
      "############## Result: 622 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Switzerland's Financial Sector Faces Major Scr...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiqwFBV...</td>\n",
       "      <td>2025-02-06 17:25:51+00:00</td>\n",
       "      <td>Evrim Ağacı</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>International Investors File Claims Against Sw...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitAFBV...</td>\n",
       "      <td>2025-02-07 08:00:00+00:00</td>\n",
       "      <td>Evrim Ağacı</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>UBS whistleblower verdict thrown out despite U...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiugFBV...</td>\n",
       "      <td>2025-02-10 08:00:00+00:00</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2nd Circ. Backs UBS In Retaliation Case That J...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMivgFBV...</td>\n",
       "      <td>2025-02-10 20:12:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Axsome therapeutics CFO sells $1.95 million in...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiywFBV...</td>\n",
       "      <td>2025-02-15 03:38:31+00:00</td>\n",
       "      <td>MSN</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "617  Switzerland's Financial Sector Faces Major Scr...   \n",
       "618  International Investors File Claims Against Sw...   \n",
       "619  UBS whistleblower verdict thrown out despite U...   \n",
       "620  2nd Circ. Backs UBS In Retaliation Case That J...   \n",
       "621  Axsome therapeutics CFO sells $1.95 million in...   \n",
       "\n",
       "                                                  link  \\\n",
       "617  https://news.google.com/rss/articles/CBMiqwFBV...   \n",
       "618  https://news.google.com/rss/articles/CBMitAFBV...   \n",
       "619  https://news.google.com/rss/articles/CBMiugFBV...   \n",
       "620  https://news.google.com/rss/articles/CBMivgFBV...   \n",
       "621  https://news.google.com/rss/articles/CBMiywFBV...   \n",
       "\n",
       "                      pubDate       source  \\\n",
       "617 2025-02-06 17:25:51+00:00  Evrim Ağacı   \n",
       "618 2025-02-07 08:00:00+00:00  Evrim Ağacı   \n",
       "619 2025-02-10 08:00:00+00:00      Reuters   \n",
       "620 2025-02-10 20:12:00+00:00       Law360   \n",
       "621 2025-02-15 03:38:31+00:00          MSN   \n",
       "\n",
       "                                           description  \n",
       "617  <a href=\"https://news.google.com/rss/articles/...  \n",
       "618  <a href=\"https://news.google.com/rss/articles/...  \n",
       "619  <a href=\"https://news.google.com/rss/articles/...  \n",
       "620  <a href=\"https://news.google.com/rss/articles/...  \n",
       "621  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219095309.json\n",
      "Saved pickle to: ./data/scrape_result_20250219095309.pkl\n",
      "-------------- Citibank  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 0, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 0, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 0, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 0, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 0, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 0, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 0, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 0, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 0, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 0, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 0, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 1, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 1, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 1, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 3, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 3, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 3, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 3, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 5, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 5, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 5, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 5, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 5, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 10, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 12, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 13, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 13, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 14, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 17, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 19, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 22, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 22, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 24, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 29, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 33, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 40, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 43, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 50, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 61, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 66, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 67, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 76, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 82, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 94, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 99, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 109, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 111, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 114, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 122, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 139, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 149, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 162, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 169, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 195, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 213, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 250, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 319, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 407, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 488, iter: 305\n",
      "############## Result: 515 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>DC Law Firms Saw Revenue and PEP Up 9% Last Ye...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMixgFBV...</td>\n",
       "      <td>2025-02-12 20:09:00+00:00</td>\n",
       "      <td>Law.com</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>FEMA funding fracas in NYC - POLITICO</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiugFBV...</td>\n",
       "      <td>2025-02-12 22:42:25+00:00</td>\n",
       "      <td>POLITICO</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Trump’s Funding Freeze Raises a New Question: ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMivAFBV...</td>\n",
       "      <td>2025-02-14 14:48:01+00:00</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Citibank Class Action Settlement Payout 2025: ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMid0FVX...</td>\n",
       "      <td>2025-02-15 11:02:11+00:00</td>\n",
       "      <td>Bakhtiyarpur College of ...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Kossoff Ch. 7 Trustee Can Pursue Clawbacks Aft...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMipgFBV...</td>\n",
       "      <td>2025-02-18 21:12:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "510  DC Law Firms Saw Revenue and PEP Up 9% Last Ye...   \n",
       "511              FEMA funding fracas in NYC - POLITICO   \n",
       "512  Trump’s Funding Freeze Raises a New Question: ...   \n",
       "513  Citibank Class Action Settlement Payout 2025: ...   \n",
       "514  Kossoff Ch. 7 Trustee Can Pursue Clawbacks Aft...   \n",
       "\n",
       "                                                  link  \\\n",
       "510  https://news.google.com/rss/articles/CBMixgFBV...   \n",
       "511  https://news.google.com/rss/articles/CBMiugFBV...   \n",
       "512  https://news.google.com/rss/articles/CBMivAFBV...   \n",
       "513  https://news.google.com/rss/articles/CBMid0FVX...   \n",
       "514  https://news.google.com/rss/articles/CBMipgFBV...   \n",
       "\n",
       "                      pubDate                       source  \\\n",
       "510 2025-02-12 20:09:00+00:00                      Law.com   \n",
       "511 2025-02-12 22:42:25+00:00                     POLITICO   \n",
       "512 2025-02-14 14:48:01+00:00           The New York Times   \n",
       "513 2025-02-15 11:02:11+00:00  Bakhtiyarpur College of ...   \n",
       "514 2025-02-18 21:12:00+00:00                       Law360   \n",
       "\n",
       "                                           description  \n",
       "510  <a href=\"https://news.google.com/rss/articles/...  \n",
       "511  <a href=\"https://news.google.com/rss/articles/...  \n",
       "512  <a href=\"https://news.google.com/rss/articles/...  \n",
       "513  <a href=\"https://news.google.com/rss/articles/...  \n",
       "514  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219095734.json\n",
      "Saved pickle to: ./data/scrape_result_20250219095734.pkl\n",
      "-------------- HSBC  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 0, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 0, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 0, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 0, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 0, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 0, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 0, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 0, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 0, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 0, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 0, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 0, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 0, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 0, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 0, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 0, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 0, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 1, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 2, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 2, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 3, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 3, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 3, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 5, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 8, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 10, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 10, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 12, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 16, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 22, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 29, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 31, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 36, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 40, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 55, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 63, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 70, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 75, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 81, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 83, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 85, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 96, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 103, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 106, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 110, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 122, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 127, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 133, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 145, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 160, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 176, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 201, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 217, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 244, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 303, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 343, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 422, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 491, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 580, iter: 305\n",
      "############## Result: 591 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Hogan Lovells Hires Financial Crime Pro From H...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMikwFBV...</td>\n",
       "      <td>2025-01-29 08:00:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Sun Pharma shares in focus: Jefferies, HSBC bu...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi0wFBV...</td>\n",
       "      <td>2025-02-01 01:53:33+00:00</td>\n",
       "      <td>Business Upturn</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Lebanon sues HSBC Switzerland in Riad Salameh ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMikAFBV...</td>\n",
       "      <td>2025-02-05 08:00:00+00:00</td>\n",
       "      <td>The New Arab</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>B.C. Court of Appeal overturns lower court, ce...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi1wFBV...</td>\n",
       "      <td>2025-02-06 21:56:15+00:00</td>\n",
       "      <td>Law360 Canada</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>HSBC Seeks To Quash Discrimination, Whistleblo...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimwFBV...</td>\n",
       "      <td>2025-02-07 17:46:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "586  Hogan Lovells Hires Financial Crime Pro From H...   \n",
       "587  Sun Pharma shares in focus: Jefferies, HSBC bu...   \n",
       "588  Lebanon sues HSBC Switzerland in Riad Salameh ...   \n",
       "589  B.C. Court of Appeal overturns lower court, ce...   \n",
       "590  HSBC Seeks To Quash Discrimination, Whistleblo...   \n",
       "\n",
       "                                                  link  \\\n",
       "586  https://news.google.com/rss/articles/CBMikwFBV...   \n",
       "587  https://news.google.com/rss/articles/CBMi0wFBV...   \n",
       "588  https://news.google.com/rss/articles/CBMikAFBV...   \n",
       "589  https://news.google.com/rss/articles/CBMi1wFBV...   \n",
       "590  https://news.google.com/rss/articles/CBMimwFBV...   \n",
       "\n",
       "                      pubDate           source  \\\n",
       "586 2025-01-29 08:00:00+00:00           Law360   \n",
       "587 2025-02-01 01:53:33+00:00  Business Upturn   \n",
       "588 2025-02-05 08:00:00+00:00     The New Arab   \n",
       "589 2025-02-06 21:56:15+00:00    Law360 Canada   \n",
       "590 2025-02-07 17:46:00+00:00           Law360   \n",
       "\n",
       "                                           description  \n",
       "586  <a href=\"https://news.google.com/rss/articles/...  \n",
       "587  <a href=\"https://news.google.com/rss/articles/...  \n",
       "588  <a href=\"https://news.google.com/rss/articles/...  \n",
       "589  <a href=\"https://news.google.com/rss/articles/...  \n",
       "590  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219100200.json\n",
      "Saved pickle to: ./data/scrape_result_20250219100200.pkl\n",
      "-------------- JPMorgan  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 0, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 0, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 0, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 0, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 0, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 0, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 0, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 1, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 1, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 1, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 2, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 2, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 3, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 4, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 5, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 5, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 5, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 5, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 6, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 6, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 6, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 7, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 9, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 10, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 13, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 17, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 18, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 21, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 25, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 31, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 37, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 66, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 80, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 89, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 94, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 103, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 113, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 121, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 130, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 140, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 149, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 162, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 168, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 181, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 189, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 204, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 214, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 222, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 232, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 244, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 269, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 317, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 344, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 373, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 496, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 664, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 820, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 989, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 1152, iter: 305\n",
      "############## Result: 1200 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>Exclusive: JPMorgan CEO Dimon derides in-offic...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMivwFBV...</td>\n",
       "      <td>2025-02-13 17:42:33+00:00</td>\n",
       "      <td>Reuters.com</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Bausch Health to Participate in the J.P. Morga...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi_AFBV...</td>\n",
       "      <td>2025-02-14 13:12:11+00:00</td>\n",
       "      <td>The Globe and Mail</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Ex-JPMorgan Atty Pleads Guilty To NYC Housing ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiowFBV...</td>\n",
       "      <td>2025-02-14 20:28:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>JPMORGAN CHASE &amp; CO SEC 10-K Report - TradingView</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimwFBV...</td>\n",
       "      <td>2025-02-14 21:28:01+00:00</td>\n",
       "      <td>TradingView</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>The dark art of deregulating - The Banker</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiekFVX...</td>\n",
       "      <td>2025-02-18 09:57:37+00:00</td>\n",
       "      <td>The Banker</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1195  Exclusive: JPMorgan CEO Dimon derides in-offic...   \n",
       "1196  Bausch Health to Participate in the J.P. Morga...   \n",
       "1197  Ex-JPMorgan Atty Pleads Guilty To NYC Housing ...   \n",
       "1198  JPMORGAN CHASE & CO SEC 10-K Report - TradingView   \n",
       "1199          The dark art of deregulating - The Banker   \n",
       "\n",
       "                                                   link  \\\n",
       "1195  https://news.google.com/rss/articles/CBMivwFBV...   \n",
       "1196  https://news.google.com/rss/articles/CBMi_AFBV...   \n",
       "1197  https://news.google.com/rss/articles/CBMiowFBV...   \n",
       "1198  https://news.google.com/rss/articles/CBMimwFBV...   \n",
       "1199  https://news.google.com/rss/articles/CBMiekFVX...   \n",
       "\n",
       "                       pubDate              source  \\\n",
       "1195 2025-02-13 17:42:33+00:00         Reuters.com   \n",
       "1196 2025-02-14 13:12:11+00:00  The Globe and Mail   \n",
       "1197 2025-02-14 20:28:00+00:00              Law360   \n",
       "1198 2025-02-14 21:28:01+00:00         TradingView   \n",
       "1199 2025-02-18 09:57:37+00:00          The Banker   \n",
       "\n",
       "                                            description  \n",
       "1195  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1196  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1197  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1198  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1199  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219100630.json\n",
      "Saved pickle to: ./data/scrape_result_20250219100630.pkl\n",
      "-------------- Goldman Sachs  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 0, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 0, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 0, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 0, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 0, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 0, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 0, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 0, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 0, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 0, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 0, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 0, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 1, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 2, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 2, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 2, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 2, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 2, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 4, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 5, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 8, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 9, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 11, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 14, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 20, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 25, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 30, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 36, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 46, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 52, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 67, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 78, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 84, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 91, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 98, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 111, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 124, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 139, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 155, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 175, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 185, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 213, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 230, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 250, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 277, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 306, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 344, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 374, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 404, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 464, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 527, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 585, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 663, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 742, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 879, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 1050, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 1231, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 1434, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 1631, iter: 305\n",
      "############## Result: 1691 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>Tesla’s $1B Lawsuit Against Matthews Dismissed...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMimgFBV...</td>\n",
       "      <td>2025-02-18 13:14:07+00:00</td>\n",
       "      <td>PUNE.NEWS</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>Competition Group Of The Year: Covington - Law360</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiUEFVX...</td>\n",
       "      <td>2025-02-18 21:03:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>Complex Financial Instruments Group Of The Yea...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiUEFVX...</td>\n",
       "      <td>2025-02-18 21:03:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>Ex-Goldman Atty Squires Expected To Be Named U...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiowFBV...</td>\n",
       "      <td>2025-02-18 21:12:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>Fund Formation Group Of The Year: Fried Frank ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMipwFBV...</td>\n",
       "      <td>2025-02-18 21:28:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1686  Tesla’s $1B Lawsuit Against Matthews Dismissed...   \n",
       "1687  Competition Group Of The Year: Covington - Law360   \n",
       "1688  Complex Financial Instruments Group Of The Yea...   \n",
       "1689  Ex-Goldman Atty Squires Expected To Be Named U...   \n",
       "1690  Fund Formation Group Of The Year: Fried Frank ...   \n",
       "\n",
       "                                                   link  \\\n",
       "1686  https://news.google.com/rss/articles/CBMimgFBV...   \n",
       "1687  https://news.google.com/rss/articles/CBMiUEFVX...   \n",
       "1688  https://news.google.com/rss/articles/CBMiUEFVX...   \n",
       "1689  https://news.google.com/rss/articles/CBMiowFBV...   \n",
       "1690  https://news.google.com/rss/articles/CBMipwFBV...   \n",
       "\n",
       "                       pubDate     source  \\\n",
       "1686 2025-02-18 13:14:07+00:00  PUNE.NEWS   \n",
       "1687 2025-02-18 21:03:00+00:00     Law360   \n",
       "1688 2025-02-18 21:03:00+00:00     Law360   \n",
       "1689 2025-02-18 21:12:00+00:00     Law360   \n",
       "1690 2025-02-18 21:28:00+00:00     Law360   \n",
       "\n",
       "                                            description  \n",
       "1686  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1687  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1688  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1689  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1690  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219101105.json\n",
      "Saved pickle to: ./data/scrape_result_20250219101105.pkl\n",
      "-------------- Credit Suisse  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 1, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 1, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 1, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 1, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 1, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 2, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 2, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 2, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 2, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 2, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 3, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 3, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 3, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 4, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 5, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 5, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 5, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 5, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 5, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 6, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 6, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 7, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 7, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 8, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 9, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 9, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 9, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 12, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 18, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 20, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 23, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 28, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 30, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 35, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 41, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 48, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 50, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 56, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 65, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 75, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 88, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 94, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 102, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 112, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 125, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 132, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 138, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 157, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 168, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 179, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 203, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 223, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 265, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 308, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 346, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 420, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 473, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 524, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 576, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 622, iter: 305\n",
      "############## Result: 635 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>International Investors File Claims Against Sw...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitAFBV...</td>\n",
       "      <td>2025-02-07 08:00:00+00:00</td>\n",
       "      <td>Evrim Ağacı</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Greensill files disqualification bid against j...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiogFBV...</td>\n",
       "      <td>2025-02-10 16:50:14+00:00</td>\n",
       "      <td>Lawyerly</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Greenpeace files lawsuit against US pipeline c...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiuAFBV...</td>\n",
       "      <td>2025-02-11 17:59:18+00:00</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Greenpeace files lawsuit against US pipeline c...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiugFBV...</td>\n",
       "      <td>2025-02-12 03:12:11+00:00</td>\n",
       "      <td>MSN</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Judge who acted in ‘hot contest’ shouldn’t hea...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiswFBV...</td>\n",
       "      <td>2025-02-14 15:00:38+00:00</td>\n",
       "      <td>Lawyerly</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "630  International Investors File Claims Against Sw...   \n",
       "631  Greensill files disqualification bid against j...   \n",
       "632  Greenpeace files lawsuit against US pipeline c...   \n",
       "633  Greenpeace files lawsuit against US pipeline c...   \n",
       "634  Judge who acted in ‘hot contest’ shouldn’t hea...   \n",
       "\n",
       "                                                  link  \\\n",
       "630  https://news.google.com/rss/articles/CBMitAFBV...   \n",
       "631  https://news.google.com/rss/articles/CBMiogFBV...   \n",
       "632  https://news.google.com/rss/articles/CBMiuAFBV...   \n",
       "633  https://news.google.com/rss/articles/CBMiugFBV...   \n",
       "634  https://news.google.com/rss/articles/CBMiswFBV...   \n",
       "\n",
       "                      pubDate       source  \\\n",
       "630 2025-02-07 08:00:00+00:00  Evrim Ağacı   \n",
       "631 2025-02-10 16:50:14+00:00     Lawyerly   \n",
       "632 2025-02-11 17:59:18+00:00      Reuters   \n",
       "633 2025-02-12 03:12:11+00:00          MSN   \n",
       "634 2025-02-14 15:00:38+00:00     Lawyerly   \n",
       "\n",
       "                                           description  \n",
       "630  <a href=\"https://news.google.com/rss/articles/...  \n",
       "631  <a href=\"https://news.google.com/rss/articles/...  \n",
       "632  <a href=\"https://news.google.com/rss/articles/...  \n",
       "633  <a href=\"https://news.google.com/rss/articles/...  \n",
       "634  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219101532.json\n",
      "Saved pickle to: ./data/scrape_result_20250219101532.pkl\n",
      "-------------- Deutsche Bank  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 1, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 1, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 1, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 1, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 1, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 1, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 2, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 2, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 3, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 3, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 4, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 5, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 6, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 6, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 7, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 7, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 8, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 9, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 10, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 11, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 11, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 12, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 12, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 17, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 19, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 22, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 23, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 26, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 35, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 40, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 46, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 53, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 60, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 70, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 80, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 89, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 106, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 126, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 153, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 180, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 198, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 215, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 238, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 255, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 285, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 322, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 350, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 381, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 417, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 438, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 471, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 521, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 562, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 608, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 697, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 801, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 938, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 1077, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 1198, iter: 305\n",
      "############## Result: 1231 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>High Court win for law firm over billionaire’s...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiygFBV...</td>\n",
       "      <td>2025-02-06 08:00:00+00:00</td>\n",
       "      <td>The Australian Financial Review</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>GSK PLC Stockholder Notice: Shareholder Rights...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMipwJBV...</td>\n",
       "      <td>2025-02-06 08:00:00+00:00</td>\n",
       "      <td>GlobeNewswire</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Mizuho raises Axsome stock target to $195, mai...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMivAFBV...</td>\n",
       "      <td>2025-02-12 06:16:02+00:00</td>\n",
       "      <td>Investing.com Nigeria</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Axsome therapeutics CFO sells $1.95 million in...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitgFBV...</td>\n",
       "      <td>2025-02-15 02:39:34+00:00</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>INVESTOR ALERT: Faruqi &amp; Faruqi, LLP Investiga...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi2AFBV...</td>\n",
       "      <td>2025-02-19 00:18:31+00:00</td>\n",
       "      <td>Markets Insider</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1226  High Court win for law firm over billionaire’s...   \n",
       "1227  GSK PLC Stockholder Notice: Shareholder Rights...   \n",
       "1228  Mizuho raises Axsome stock target to $195, mai...   \n",
       "1229  Axsome therapeutics CFO sells $1.95 million in...   \n",
       "1230  INVESTOR ALERT: Faruqi & Faruqi, LLP Investiga...   \n",
       "\n",
       "                                                   link  \\\n",
       "1226  https://news.google.com/rss/articles/CBMiygFBV...   \n",
       "1227  https://news.google.com/rss/articles/CBMipwJBV...   \n",
       "1228  https://news.google.com/rss/articles/CBMivAFBV...   \n",
       "1229  https://news.google.com/rss/articles/CBMitgFBV...   \n",
       "1230  https://news.google.com/rss/articles/CBMi2AFBV...   \n",
       "\n",
       "                       pubDate                           source  \\\n",
       "1226 2025-02-06 08:00:00+00:00  The Australian Financial Review   \n",
       "1227 2025-02-06 08:00:00+00:00                    GlobeNewswire   \n",
       "1228 2025-02-12 06:16:02+00:00            Investing.com Nigeria   \n",
       "1229 2025-02-15 02:39:34+00:00                    Investing.com   \n",
       "1230 2025-02-19 00:18:31+00:00                  Markets Insider   \n",
       "\n",
       "                                            description  \n",
       "1226  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1227  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1228  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1229  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1230  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219102003.json\n",
      "Saved pickle to: ./data/scrape_result_20250219102003.pkl\n",
      "-------------- Barclays  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 1, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 1, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 1, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 1, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 1, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 1, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 1, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 2, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 2, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 2, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 2, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 2, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 2, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 2, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 2, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 2, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 2, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 2, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 3, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 6, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 6, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 8, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 12, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 12, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 12, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 13, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 13, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 15, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 23, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 28, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 31, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 35, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 47, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 52, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 53, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 65, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 72, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 85, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 93, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 104, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 113, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 129, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 143, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 162, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 176, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 198, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 207, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 240, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 266, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 292, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 302, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 328, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 364, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 390, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 448, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 519, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 619, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 715, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 838, iter: 305\n",
      "############## Result: 857 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Barclays' Q4 Earnings Up on Solid IB, 2025 NII...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMigAFBV...</td>\n",
       "      <td>2025-02-13 12:40:00+00:00</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Barclays: Strong Revenue Growth and Solid Outl...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiqAFBV...</td>\n",
       "      <td>2025-02-13 13:01:46+00:00</td>\n",
       "      <td>TipRanks</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>Barclays Reveals FCA Probe Over Money Launderi...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitwFBV...</td>\n",
       "      <td>2025-02-13 19:26:00+00:00</td>\n",
       "      <td>Law360</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Barclays reserves £90m for motor finance claim...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMinAFBV...</td>\n",
       "      <td>2025-02-14 10:36:43+00:00</td>\n",
       "      <td>Law Gazette</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>General counsels describe internal investigati...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi4wFBV...</td>\n",
       "      <td>2025-02-18 12:26:30+00:00</td>\n",
       "      <td>Global Investigations Review</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "852  Barclays' Q4 Earnings Up on Solid IB, 2025 NII...   \n",
       "853  Barclays: Strong Revenue Growth and Solid Outl...   \n",
       "854  Barclays Reveals FCA Probe Over Money Launderi...   \n",
       "855  Barclays reserves £90m for motor finance claim...   \n",
       "856  General counsels describe internal investigati...   \n",
       "\n",
       "                                                  link  \\\n",
       "852  https://news.google.com/rss/articles/CBMigAFBV...   \n",
       "853  https://news.google.com/rss/articles/CBMiqAFBV...   \n",
       "854  https://news.google.com/rss/articles/CBMitwFBV...   \n",
       "855  https://news.google.com/rss/articles/CBMinAFBV...   \n",
       "856  https://news.google.com/rss/articles/CBMi4wFBV...   \n",
       "\n",
       "                      pubDate                        source  \\\n",
       "852 2025-02-13 12:40:00+00:00                 Yahoo Finance   \n",
       "853 2025-02-13 13:01:46+00:00                      TipRanks   \n",
       "854 2025-02-13 19:26:00+00:00                        Law360   \n",
       "855 2025-02-14 10:36:43+00:00                   Law Gazette   \n",
       "856 2025-02-18 12:26:30+00:00  Global Investigations Review   \n",
       "\n",
       "                                           description  \n",
       "852  <a href=\"https://news.google.com/rss/articles/...  \n",
       "853  <a href=\"https://news.google.com/rss/articles/...  \n",
       "854  <a href=\"https://news.google.com/rss/articles/...  \n",
       "855  <a href=\"https://news.google.com/rss/articles/...  \n",
       "856  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219102428.json\n",
      "Saved pickle to: ./data/scrape_result_20250219102428.pkl\n",
      "-------------- Bank of America  --------------\n",
      "-- Current state: 2000-05-30-2000-05-29, record_count: 0, iter: 5\n",
      "-- Current state: 2000-10-27-2000-10-26, record_count: 0, iter: 10\n",
      "-- Current state: 2001-03-26-2001-03-25, record_count: 0, iter: 15\n",
      "-- Current state: 2001-08-23-2001-08-22, record_count: 1, iter: 20\n",
      "-- Current state: 2002-01-20-2002-01-19, record_count: 1, iter: 25\n",
      "-- Current state: 2002-06-19-2002-06-18, record_count: 1, iter: 30\n",
      "-- Current state: 2002-11-16-2002-11-15, record_count: 1, iter: 35\n",
      "-- Current state: 2003-04-15-2003-04-14, record_count: 1, iter: 40\n",
      "-- Current state: 2003-09-12-2003-09-11, record_count: 1, iter: 45\n",
      "-- Current state: 2004-02-09-2004-02-08, record_count: 1, iter: 50\n",
      "-- Current state: 2004-07-08-2004-07-07, record_count: 3, iter: 55\n",
      "-- Current state: 2004-12-05-2004-12-04, record_count: 3, iter: 60\n",
      "-- Current state: 2005-05-04-2005-05-03, record_count: 4, iter: 65\n",
      "-- Current state: 2005-10-01-2005-09-30, record_count: 5, iter: 70\n",
      "-- Current state: 2006-02-28-2006-02-27, record_count: 7, iter: 75\n",
      "-- Current state: 2006-07-28-2006-07-27, record_count: 7, iter: 80\n",
      "-- Current state: 2006-12-25-2006-12-24, record_count: 7, iter: 85\n",
      "-- Current state: 2007-05-24-2007-05-23, record_count: 9, iter: 90\n",
      "-- Current state: 2007-10-21-2007-10-20, record_count: 10, iter: 95\n",
      "-- Current state: 2008-03-19-2008-03-18, record_count: 10, iter: 100\n",
      "-- Current state: 2008-08-16-2008-08-15, record_count: 13, iter: 105\n",
      "-- Current state: 2009-01-13-2009-01-12, record_count: 15, iter: 110\n",
      "-- Current state: 2009-06-12-2009-06-11, record_count: 19, iter: 115\n",
      "-- Current state: 2009-11-09-2009-11-08, record_count: 23, iter: 120\n",
      "-- Current state: 2010-04-08-2010-04-07, record_count: 26, iter: 125\n",
      "-- Current state: 2010-09-05-2010-09-04, record_count: 29, iter: 130\n",
      "-- Current state: 2011-02-02-2011-02-01, record_count: 36, iter: 135\n",
      "-- Current state: 2011-07-02-2011-07-01, record_count: 51, iter: 140\n",
      "-- Current state: 2011-11-29-2011-11-28, record_count: 64, iter: 145\n",
      "-- Current state: 2012-04-27-2012-04-26, record_count: 74, iter: 150\n",
      "-- Current state: 2012-09-24-2012-09-23, record_count: 89, iter: 155\n",
      "-- Current state: 2013-02-21-2013-02-20, record_count: 109, iter: 160\n",
      "-- Current state: 2013-07-21-2013-07-20, record_count: 125, iter: 165\n",
      "-- Current state: 2013-12-18-2013-12-17, record_count: 154, iter: 170\n",
      "-- Current state: 2014-05-17-2014-05-16, record_count: 174, iter: 175\n",
      "-- Current state: 2014-10-14-2014-10-13, record_count: 197, iter: 180\n",
      "-- Current state: 2015-03-13-2015-03-12, record_count: 215, iter: 185\n",
      "-- Current state: 2015-08-10-2015-08-09, record_count: 242, iter: 190\n",
      "-- Current state: 2016-01-07-2016-01-06, record_count: 267, iter: 195\n",
      "-- Current state: 2016-06-05-2016-06-04, record_count: 301, iter: 200\n",
      "-- Current state: 2016-11-02-2016-11-01, record_count: 329, iter: 205\n",
      "-- Current state: 2017-04-01-2017-03-31, record_count: 347, iter: 210\n",
      "-- Current state: 2017-08-29-2017-08-28, record_count: 370, iter: 215\n",
      "-- Current state: 2018-01-26-2018-01-25, record_count: 404, iter: 220\n",
      "-- Current state: 2018-06-25-2018-06-24, record_count: 436, iter: 225\n",
      "-- Current state: 2018-11-22-2018-11-21, record_count: 476, iter: 230\n",
      "-- Current state: 2019-04-21-2019-04-20, record_count: 502, iter: 235\n",
      "-- Current state: 2019-09-18-2019-09-17, record_count: 538, iter: 240\n",
      "-- Current state: 2020-02-15-2020-02-14, record_count: 585, iter: 245\n",
      "-- Current state: 2020-07-14-2020-07-13, record_count: 630, iter: 250\n",
      "-- Current state: 2020-12-11-2020-12-10, record_count: 678, iter: 255\n",
      "-- Current state: 2021-05-10-2021-05-09, record_count: 731, iter: 260\n",
      "-- Current state: 2021-10-07-2021-10-06, record_count: 801, iter: 265\n",
      "-- Current state: 2022-03-06-2022-03-05, record_count: 872, iter: 270\n",
      "-- Current state: 2022-08-03-2022-08-02, record_count: 949, iter: 275\n",
      "-- Current state: 2022-12-31-2022-12-30, record_count: 1050, iter: 280\n",
      "-- Current state: 2023-05-30-2023-05-29, record_count: 1206, iter: 285\n",
      "-- Current state: 2023-10-27-2023-10-26, record_count: 1384, iter: 290\n",
      "-- Current state: 2024-03-25-2024-03-24, record_count: 1575, iter: 295\n",
      "-- Current state: 2024-08-22-2024-08-21, record_count: 1755, iter: 300\n",
      "-- Current state: 2025-01-19-2025-01-18, record_count: 1926, iter: 305\n",
      "############## Result: 1981 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>Peloton wins dismissal of shareholder lawsuit ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiwwFBV...</td>\n",
       "      <td>2025-02-14 23:42:57+00:00</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>Mexican president threatens to sue Google over...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiqwFBV...</td>\n",
       "      <td>2025-02-18 16:06:03+00:00</td>\n",
       "      <td>Global News Toronto</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>XRP ETF Gets A Shot! Why MEMX’s SEC Filing Is ...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiX0FVX...</td>\n",
       "      <td>2025-02-18 16:30:00+00:00</td>\n",
       "      <td>TronWeekly</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Merrill Lynch Ex-Advisers Look to Pause Deferr...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMitgFBV...</td>\n",
       "      <td>2025-02-18 18:52:00+00:00</td>\n",
       "      <td>Bloomberg Law</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>FreightCar America, Inc. Announces New $35 Mil...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMi7gFBV...</td>\n",
       "      <td>2025-02-18 21:33:04+00:00</td>\n",
       "      <td>The Manila Times</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1976  Peloton wins dismissal of shareholder lawsuit ...   \n",
       "1977  Mexican president threatens to sue Google over...   \n",
       "1978  XRP ETF Gets A Shot! Why MEMX’s SEC Filing Is ...   \n",
       "1979  Merrill Lynch Ex-Advisers Look to Pause Deferr...   \n",
       "1980  FreightCar America, Inc. Announces New $35 Mil...   \n",
       "\n",
       "                                                   link  \\\n",
       "1976  https://news.google.com/rss/articles/CBMiwwFBV...   \n",
       "1977  https://news.google.com/rss/articles/CBMiqwFBV...   \n",
       "1978  https://news.google.com/rss/articles/CBMiX0FVX...   \n",
       "1979  https://news.google.com/rss/articles/CBMitgFBV...   \n",
       "1980  https://news.google.com/rss/articles/CBMi7gFBV...   \n",
       "\n",
       "                       pubDate               source  \\\n",
       "1976 2025-02-14 23:42:57+00:00              Reuters   \n",
       "1977 2025-02-18 16:06:03+00:00  Global News Toronto   \n",
       "1978 2025-02-18 16:30:00+00:00           TronWeekly   \n",
       "1979 2025-02-18 18:52:00+00:00        Bloomberg Law   \n",
       "1980 2025-02-18 21:33:04+00:00     The Manila Times   \n",
       "\n",
       "                                            description  \n",
       "1976  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1977  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1978  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1979  <a href=\"https://news.google.com/rss/articles/...  \n",
       "1980  <a href=\"https://news.google.com/rss/articles/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219102912.json\n",
      "Saved pickle to: ./data/scrape_result_20250219102912.pkl\n"
     ]
    }
   ],
   "source": [
    "banks_arr = [\"UBS\", \"Citibank\", \"HSBC\", \"JPMorgan\", \"Goldman Sachs\", \"Credit Suisse\", \"Deutsche Bank\", \"Barclays\", \"Bank of America\"]\n",
    "for each_bank in banks_arr:\n",
    "    print(f\"-------------- {each_bank}  --------------\")\n",
    "    rss_feed_scraper.scrape(f\"{each_bank} litigation\",start_time=date(2000,1,1), save_state=True, save_result=True, preview_result=True, scrape_period = 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloomberg law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import traceback\n",
    "import time\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from datetime import datetime, timedelta, date\n",
    "from IPython.display import display\n",
    "\n",
    "class BloombergLawScraper():\n",
    "    def __init__(self, proxy=None):\n",
    "        self.proxy = proxy\n",
    "        self.state = {}\n",
    "        self.base_url = \"https://news.bloomberglaw.com/api/v1/rss/litigation?\"\n",
    "    \n",
    "    def scrape(self, search_query, start_time=datetime.now().date(), end_time = datetime.now().date(), fetch_limit=10, scrape_period = 7, add_url_parameters={}, save_state=False, save_result=False, save_folder=\"./data\", preview_result=True, sleep_interval=5):\n",
    "        \"\"\"\n",
    "        Web scrape google news rss feeds. \n",
    "        - Use date(YYYY, MM, DD) to initiate date arguments. eg: date(2025, 2, 19)\n",
    "        Args:\n",
    "            search_query (String): Search query\n",
    "            start_time (Date): Default to datetime.now(). \n",
    "            end_time (Date): Default to datetime.now(). \n",
    "            fetch_limit (int): Number of items fetch (default is 10)\n",
    "            scrape_period (int): no. of days for each scrape instance (inclusive of start and exclusive end: must be more than 1)\n",
    "            add_url_parameters (dict): Additional url parameters\n",
    "            save_state (boolean): Save state progress in json file. format: f\"/scrape_state_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "            save_result (boolean): Save dataframe as pickle file. format: f\"/scrape_result_{datetime.now().strftime('%Y%m%d%H%M%S')}.pkl\"\n",
    "            save_folder (String): root folder to save state and result\n",
    "            preview_result (boolean): Show pandas dataframe after processing\n",
    "            sleep_interval (int): Sleep for 3 seconds for every X interations (intervals).\n",
    "        \"\"\"\n",
    "        if end_time < start_time:\n",
    "            raise ValueError(\"End time must be greater than start time!\")\n",
    "        elif scrape_period < 1:\n",
    "            raise ValueError(\"Scrape period must be more than 1!\")\n",
    "        \n",
    "        # Save state\n",
    "        self.state = {\n",
    "            \"parameters\": {\n",
    "                \"search_query\": search_query,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"scrape_period\": scrape_period,\n",
    "                \"add_url_parameters\": add_url_parameters,\n",
    "                \"fetch_limit\": fetch_limit\n",
    "            },\n",
    "            \"iter_no\": 0\n",
    "        }\n",
    "        to_time = None\n",
    "        df = pd.DataFrame()\n",
    "        try:\n",
    "            while start_time <= end_time:\n",
    "                to_time = min(start_time + timedelta(days=scrape_period), end_time)\n",
    "                # Format and encode URL\n",
    "                url_parameters = {\"query\": search_query, \"startDate\": start_time.strftime('%Y-%m-%d'),\"endDate\": to_time.strftime('%Y-%m-%d'), \"limit\": fetch_limit, **add_url_parameters}\n",
    "                url = self.base_url + urllib.parse.urlencode(url_parameters)\n",
    "\n",
    "                self.state[\"to_time\"] = to_time\n",
    "                self.state[\"url\"] = url\n",
    "                \n",
    "                # GET request and parse\n",
    "                df_intermediate = self.fetch_and_parse(url, pandas= True)\n",
    "                if len(df_intermediate) > 0:\n",
    "                    df = pd.concat([df,df_intermediate])\n",
    "                    df.drop_duplicates(subset=[\"pubDate\", \"title\"], inplace=True)\n",
    "                    df.sort_values(by='pubDate', inplace=True)\n",
    "                    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                self.state[\"iter_no\"] += 1\n",
    "                if self.state[\"iter_no\"] % sleep_interval == 0:\n",
    "                    print(f\"-- Current state: {start_time}-{to_time}, record_count: {len(df)}, iter: {self.state['iter_no']}\")\n",
    "                    time.sleep(3)\n",
    "                start_time += timedelta(days=scrape_period) \n",
    "        except Exception as e:\n",
    "            print(f\"########## Error: {start_time}-{to_time} {end_time} #########\")\n",
    "            print(traceback.format_exc())\n",
    "        finally:\n",
    "            self.state[\"record_count\"] = len(df)\n",
    "            if preview_result:\n",
    "                print(f\"############## Result: {len(df)} records ##############\")\n",
    "                display(df.tail())\n",
    "            if save_state:\n",
    "                save_path = save_folder.rstrip(\"/\") + f\"/scrape_state_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "                self.state[\"save_state_path\"] = save_path\n",
    "                with open(save_path, \"w\") as f:\n",
    "                    json.dump(self.state, f, indent=4, default=str)\n",
    "                print(\"Saved state to:\", save_path)\n",
    "            if save_result and len(df) > 0:\n",
    "                save_path = save_folder.rstrip(\"/\") + f\"/scrape_result_{datetime.now().strftime('%Y%m%d%H%M%S')}.pkl\"\n",
    "                self.state[\"save_result_path\"] = save_path\n",
    "                df.to_pickle(save_path)\n",
    "                print(\"Saved pickle to:\", save_path)\n",
    "            \n",
    "\n",
    "    def fetch_and_parse(self, url, pandas= True):\n",
    "        response = requests.get(url, proxies=self.proxy) \n",
    "        soup = bs.BeautifulSoup(response.text,'xml')\n",
    "\n",
    "        result = []\n",
    "        for item in soup.find_all('item'):\n",
    "            result.append({\n",
    "                \"title\": item.title.text,\n",
    "                \"link\": item.link.text,\n",
    "                \"pubDate\": item.pubDate.text,\n",
    "                \"description\": item.description.text,\n",
    "                \"topic\": list(map(lambda x: x.text, item.find_all('md:topic')))\n",
    "            })\n",
    "        if pandas:\n",
    "            if len(result) == 0:\n",
    "                return pd.DataFrame()\n",
    "            df = pd.DataFrame(result)\n",
    "            df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z', utc=True)\n",
    "            return df\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloombergLawScraper = BloombergLawScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- UBS  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n",
      "-- Current state: 2020-11-11-2020-12-11, record_count: 2, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 6, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 15, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 24, iter: 270\n",
      "-- Current state: 2022-07-04-2022-08-03, record_count: 34, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 44, iter: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2023-04-30-2023-05-30, record_count: 59, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 89, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 106, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 158, iter: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-12-20-2025-01-19, record_count: 176, iter: 305\n",
      "############## Result: 182 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Archegos CFO Gets Eight Years in Prison for De...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/arche...</td>\n",
       "      <td>2025-01-27 14:21:13-05:00</td>\n",
       "      <td>Former Archegos Capital Management CFO Patrick...</td>\n",
       "      <td>[witnesses, market manipulation, sentencing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Serta Lenders Seek Full Appeals Court Review o...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/serta...</td>\n",
       "      <td>2025-02-05 15:57:46-05:00</td>\n",
       "      <td>A group of lenders who participated in the con...</td>\n",
       "      <td>[confirmation of plan, indemnification, natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>UBS Whistleblower’s Trial Win Axed Over Unfit ...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/ubs-w...</td>\n",
       "      <td>2025-02-10 15:52:23-05:00</td>\n",
       "      <td>A former UBS Group AG researcher saw his trial...</td>\n",
       "      <td>[whistleblowing by employee, damages, reductio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Credit Suisse Volatility Index Investors Get A...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/credi...</td>\n",
       "      <td>2025-02-12 15:01:34-05:00</td>\n",
       "      <td>UBS unit Credit Suisse Group AG faces an addit...</td>\n",
       "      <td>[market manipulation, class certification, lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ComEd Four Seek Stay in Madigan Bribery Case P...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/comed...</td>\n",
       "      <td>2025-02-18 12:11:19-05:00</td>\n",
       "      <td>Four former Commonwealth Edison executives and...</td>\n",
       "      <td>[state environmental legislation, sentencing, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "177  Archegos CFO Gets Eight Years in Prison for De...   \n",
       "178  Serta Lenders Seek Full Appeals Court Review o...   \n",
       "179  UBS Whistleblower’s Trial Win Axed Over Unfit ...   \n",
       "180  Credit Suisse Volatility Index Investors Get A...   \n",
       "181  ComEd Four Seek Stay in Madigan Bribery Case P...   \n",
       "\n",
       "                                                  link  \\\n",
       "177  https://news.bloomberglaw.com/litigation/arche...   \n",
       "178  https://news.bloomberglaw.com/litigation/serta...   \n",
       "179  https://news.bloomberglaw.com/litigation/ubs-w...   \n",
       "180  https://news.bloomberglaw.com/litigation/credi...   \n",
       "181  https://news.bloomberglaw.com/litigation/comed...   \n",
       "\n",
       "                       pubDate  \\\n",
       "177  2025-01-27 14:21:13-05:00   \n",
       "178  2025-02-05 15:57:46-05:00   \n",
       "179  2025-02-10 15:52:23-05:00   \n",
       "180  2025-02-12 15:01:34-05:00   \n",
       "181  2025-02-18 12:11:19-05:00   \n",
       "\n",
       "                                           description  \\\n",
       "177  Former Archegos Capital Management CFO Patrick...   \n",
       "178  A group of lenders who participated in the con...   \n",
       "179  A former UBS Group AG researcher saw his trial...   \n",
       "180  UBS unit Credit Suisse Group AG faces an addit...   \n",
       "181  Four former Commonwealth Edison executives and...   \n",
       "\n",
       "                                                 topic  \n",
       "177       [witnesses, market manipulation, sentencing]  \n",
       "178  [confirmation of plan, indemnification, natura...  \n",
       "179  [whistleblowing by employee, damages, reductio...  \n",
       "180  [market manipulation, class certification, lea...  \n",
       "181  [state environmental legislation, sentencing, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219121917.json\n",
      "Saved pickle to: ./data/scrape_result_20250219121917.pkl\n",
      "-------------- Citibank  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n",
      "-- Current state: 2020-11-11-2020-12-11, record_count: 1, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 4, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 5, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 9, iter: 270\n",
      "-- Current state: 2022-07-04-2022-08-03, record_count: 13, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 16, iter: 280\n",
      "-- Current state: 2023-04-30-2023-05-30, record_count: 16, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 23, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 34, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 46, iter: 300\n",
      "-- Current state: 2024-12-20-2025-01-19, record_count: 56, iter: 305\n",
      "############## Result: 58 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Property Manager Can’t Block Bank Records Subp...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/prope...</td>\n",
       "      <td>2024-11-13 12:13:54-05:00</td>\n",
       "      <td>A property manager can't challenge a summons t...</td>\n",
       "      <td>[guilty pleas, restitution, indemnification, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Citi Sues Ex-Bankers, Saying They Took Client ...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/citi-...</td>\n",
       "      <td>2024-11-22 11:42:42-05:00</td>\n",
       "      <td>Citibank NA accused two private bankers of ill...</td>\n",
       "      <td>[notice, injunctions, trade secret misappropri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Citi Wins Court Order Against Ex-Banker Who Le...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/citi-...</td>\n",
       "      <td>2024-11-27 10:53:50-05:00</td>\n",
       "      <td>Citibank NA won a court order requiring a form...</td>\n",
       "      <td>[breach of contract, trade secret misappropria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Citigroup Fails to Shake New York’s Online Fra...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/citig...</td>\n",
       "      <td>2025-01-21 17:23:52-05:00</td>\n",
       "      <td>Citigroup Inc. lost its bid to avoid some clai...</td>\n",
       "      <td>[civil fraud, unfair and deceptive trade pract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Citigroup Wins Bid to Arbitrate Veterans’ Cred...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/citig...</td>\n",
       "      <td>2025-01-27 14:20:13-05:00</td>\n",
       "      <td>Citigroup Inc. can arbitrate a proposed class ...</td>\n",
       "      <td>[veterans, mandatory arbitration provisions, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "53  Property Manager Can’t Block Bank Records Subp...   \n",
       "54  Citi Sues Ex-Bankers, Saying They Took Client ...   \n",
       "55  Citi Wins Court Order Against Ex-Banker Who Le...   \n",
       "56  Citigroup Fails to Shake New York’s Online Fra...   \n",
       "57  Citigroup Wins Bid to Arbitrate Veterans’ Cred...   \n",
       "\n",
       "                                                 link  \\\n",
       "53  https://news.bloomberglaw.com/litigation/prope...   \n",
       "54  https://news.bloomberglaw.com/litigation/citi-...   \n",
       "55  https://news.bloomberglaw.com/litigation/citi-...   \n",
       "56  https://news.bloomberglaw.com/litigation/citig...   \n",
       "57  https://news.bloomberglaw.com/litigation/citig...   \n",
       "\n",
       "                      pubDate  \\\n",
       "53  2024-11-13 12:13:54-05:00   \n",
       "54  2024-11-22 11:42:42-05:00   \n",
       "55  2024-11-27 10:53:50-05:00   \n",
       "56  2025-01-21 17:23:52-05:00   \n",
       "57  2025-01-27 14:20:13-05:00   \n",
       "\n",
       "                                          description  \\\n",
       "53  A property manager can't challenge a summons t...   \n",
       "54  Citibank NA accused two private bankers of ill...   \n",
       "55  Citibank NA won a court order requiring a form...   \n",
       "56  Citigroup Inc. lost its bid to avoid some clai...   \n",
       "57  Citigroup Inc. can arbitrate a proposed class ...   \n",
       "\n",
       "                                                topic  \n",
       "53  [guilty pleas, restitution, indemnification, s...  \n",
       "54  [notice, injunctions, trade secret misappropri...  \n",
       "55  [breach of contract, trade secret misappropria...  \n",
       "56  [civil fraud, unfair and deceptive trade pract...  \n",
       "57  [veterans, mandatory arbitration provisions, c...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219122708.json\n",
      "Saved pickle to: ./data/scrape_result_20250219122708.pkl\n",
      "-------------- HSBC  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n",
      "-- Current state: 2020-11-11-2020-12-11, record_count: 5, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 11, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 17, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 26, iter: 270\n",
      "-- Current state: 2022-07-04-2022-08-03, record_count: 32, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 39, iter: 280\n",
      "-- Current state: 2023-04-30-2023-05-30, record_count: 48, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 57, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 67, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 79, iter: 300\n",
      "-- Current state: 2024-12-20-2025-01-19, record_count: 84, iter: 305\n",
      "############## Result: 87 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mexican Bank Units Must Face Bond-Manipulation...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/mexic...</td>\n",
       "      <td>2025-01-15 17:40:57-05:00</td>\n",
       "      <td>Mexican affiliates of big banks including Bank...</td>\n",
       "      <td>[dismissal, class actions, indemnification, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Lawyers in Metals Price-Fixing Case Awarded $6...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/lawye...</td>\n",
       "      <td>2025-01-17 14:09:30-05:00</td>\n",
       "      <td>Attorneys representing plaintiffs in a case cl...</td>\n",
       "      <td>[settlements, futures, attorney fee awards, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>HSBC Bank Must Pay $550,000 in Attorney Fees i...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/hsbc-...</td>\n",
       "      <td>2025-01-22 16:08:39-05:00</td>\n",
       "      <td>HSBC Bank USA will have to pay more than half ...</td>\n",
       "      <td>[settlements, credit reports, witnesses, disco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>HSBC Workers Should Lose Bid for Wage Class St...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/hsbc-...</td>\n",
       "      <td>2025-01-27 14:56:51-05:00</td>\n",
       "      <td>HSBC Bank USA NA personal bankers failed to me...</td>\n",
       "      <td>[overtime, timecards and timesheets, joinder, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>PayPal Fined for Withholding Funds in Body Sho...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/paypa...</td>\n",
       "      <td>2025-01-30 14:58:44-05:00</td>\n",
       "      <td>A judge declared PayPal Holdings, Inc. in civi...</td>\n",
       "      <td>[payment systems, bankruptcy trustees and exam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "82  Mexican Bank Units Must Face Bond-Manipulation...   \n",
       "83  Lawyers in Metals Price-Fixing Case Awarded $6...   \n",
       "84  HSBC Bank Must Pay $550,000 in Attorney Fees i...   \n",
       "85  HSBC Workers Should Lose Bid for Wage Class St...   \n",
       "86  PayPal Fined for Withholding Funds in Body Sho...   \n",
       "\n",
       "                                                 link  \\\n",
       "82  https://news.bloomberglaw.com/litigation/mexic...   \n",
       "83  https://news.bloomberglaw.com/litigation/lawye...   \n",
       "84  https://news.bloomberglaw.com/litigation/hsbc-...   \n",
       "85  https://news.bloomberglaw.com/litigation/hsbc-...   \n",
       "86  https://news.bloomberglaw.com/litigation/paypa...   \n",
       "\n",
       "                      pubDate  \\\n",
       "82  2025-01-15 17:40:57-05:00   \n",
       "83  2025-01-17 14:09:30-05:00   \n",
       "84  2025-01-22 16:08:39-05:00   \n",
       "85  2025-01-27 14:56:51-05:00   \n",
       "86  2025-01-30 14:58:44-05:00   \n",
       "\n",
       "                                          description  \\\n",
       "82  Mexican affiliates of big banks including Bank...   \n",
       "83  Attorneys representing plaintiffs in a case cl...   \n",
       "84  HSBC Bank USA will have to pay more than half ...   \n",
       "85  HSBC Bank USA NA personal bankers failed to me...   \n",
       "86  A judge declared PayPal Holdings, Inc. in civi...   \n",
       "\n",
       "                                                topic  \n",
       "82  [dismissal, class actions, indemnification, ma...  \n",
       "83  [settlements, futures, attorney fee awards, cl...  \n",
       "84  [settlements, credit reports, witnesses, disco...  \n",
       "85  [overtime, timecards and timesheets, joinder, ...  \n",
       "86  [payment systems, bankruptcy trustees and exam...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219123500.json\n",
      "Saved pickle to: ./data/scrape_result_20250219123500.pkl\n",
      "-------------- JPMorgan  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2020-11-11-2020-12-11, record_count: 24, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 36, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 60, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 81, iter: 270\n",
      "-- Current state: 2022-07-04-2022-08-03, record_count: 100, iter: 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2022-12-01-2022-12-31, record_count: 119, iter: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2023-04-30-2023-05-30, record_count: 177, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 250, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 304, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 357, iter: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-12-20-2025-01-19, record_count: 404, iter: 305\n",
      "############## Result: 420 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>JPMorgan Can Pursue Trade Secrets Suit Against...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/jpmor...</td>\n",
       "      <td>2025-02-06 14:02:50-05:00</td>\n",
       "      <td>JPMorgan Chase Bank can proceed with its feder...</td>\n",
       "      <td>[trade secret misappropriation, amendment of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Cybereason CEO Sues Mnuchin, SoftBank Fund Ove...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/cyber...</td>\n",
       "      <td>2025-02-11 13:26:36-05:00</td>\n",
       "      <td>The chief executive officer of Cybereason Inc....</td>\n",
       "      <td>[corporate officers, tax liability of debtor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>‘Greenhushing’ Emerges as Anti-ESG Pressures M...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/green...</td>\n",
       "      <td>2025-02-13 05:00:01-05:00</td>\n",
       "      <td>The Trump administration's attacks on companie...</td>\n",
       "      <td>[environmental reporting, investment professio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Judge Halts CFPB Action After Alleged Plans to...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/sensi...</td>\n",
       "      <td>2025-02-14 18:05:53-05:00</td>\n",
       "      <td>A federal judge on Friday ordered the Consumer...</td>\n",
       "      <td>[bank supervision, consumer finance, mass layo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>JPMorgan Set to Relive ‘Huge Mistake’ at Javic...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/jpmor...</td>\n",
       "      <td>2025-02-18 07:00:00-05:00</td>\n",
       "      <td>JPMorgan executives are expected to take the s...</td>\n",
       "      <td>[witnesses, securities fraud, internal investi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "415  JPMorgan Can Pursue Trade Secrets Suit Against...   \n",
       "416  Cybereason CEO Sues Mnuchin, SoftBank Fund Ove...   \n",
       "417  ‘Greenhushing’ Emerges as Anti-ESG Pressures M...   \n",
       "418  Judge Halts CFPB Action After Alleged Plans to...   \n",
       "419  JPMorgan Set to Relive ‘Huge Mistake’ at Javic...   \n",
       "\n",
       "                                                  link  \\\n",
       "415  https://news.bloomberglaw.com/litigation/jpmor...   \n",
       "416  https://news.bloomberglaw.com/litigation/cyber...   \n",
       "417  https://news.bloomberglaw.com/litigation/green...   \n",
       "418  https://news.bloomberglaw.com/litigation/sensi...   \n",
       "419  https://news.bloomberglaw.com/litigation/jpmor...   \n",
       "\n",
       "                       pubDate  \\\n",
       "415  2025-02-06 14:02:50-05:00   \n",
       "416  2025-02-11 13:26:36-05:00   \n",
       "417  2025-02-13 05:00:01-05:00   \n",
       "418  2025-02-14 18:05:53-05:00   \n",
       "419  2025-02-18 07:00:00-05:00   \n",
       "\n",
       "                                           description  \\\n",
       "415  JPMorgan Chase Bank can proceed with its feder...   \n",
       "416  The chief executive officer of Cybereason Inc....   \n",
       "417  The Trump administration's attacks on companie...   \n",
       "418  A federal judge on Friday ordered the Consumer...   \n",
       "419  JPMorgan executives are expected to take the s...   \n",
       "\n",
       "                                                 topic  \n",
       "415  [trade secret misappropriation, amendment of p...  \n",
       "416  [corporate officers, tax liability of debtor, ...  \n",
       "417  [environmental reporting, investment professio...  \n",
       "418  [bank supervision, consumer finance, mass layo...  \n",
       "419  [witnesses, securities fraud, internal investi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219124253.json\n",
      "Saved pickle to: ./data/scrape_result_20250219124253.pkl\n",
      "-------------- Goldman Sachs  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2020-11-11-2020-12-11, record_count: 8, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 22, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 45, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 63, iter: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2022-07-04-2022-08-03, record_count: 85, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 96, iter: 280\n",
      "-- Current state: 2023-04-30-2023-05-30, record_count: 125, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 163, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 208, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 259, iter: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-12-20-2025-01-19, record_count: 286, iter: 305\n",
      "############## Result: 293 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Pfizer, Anti-DEI Group End Suit Over Diversity...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/pfize...</td>\n",
       "      <td>2025-01-31 16:38:16-05:00</td>\n",
       "      <td>Pfizer Inc. and a conservative group agreed to...</td>\n",
       "      <td>[preliminary injunctions, standing, mootness, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Ex-Goldman Banker Advances Some Pay Claims Aga...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/ex-go...</td>\n",
       "      <td>2025-02-07 09:56:06-05:00</td>\n",
       "      <td>An investment banker who left Goldman Sachs &amp; ...</td>\n",
       "      <td>[investment professional compensation, resigna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>‘Greenhushing’ Emerges as Anti-ESG Pressures M...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/green...</td>\n",
       "      <td>2025-02-13 05:00:01-05:00</td>\n",
       "      <td>The Trump administration's attacks on companie...</td>\n",
       "      <td>[environmental reporting, investment professio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Judge Halts CFPB Action After Alleged Plans to...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/sensi...</td>\n",
       "      <td>2025-02-14 18:05:53-05:00</td>\n",
       "      <td>A federal judge on Friday ordered the Consumer...</td>\n",
       "      <td>[bank supervision, consumer finance, mass layo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Ozy Media CEO Hit With $96 Million Restitution...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/ozy-m...</td>\n",
       "      <td>2025-02-17 11:23:12-05:00</td>\n",
       "      <td>Ozy Media chief executive Carlos Watson and hi...</td>\n",
       "      <td>[forfeiture, corporate officers, securities fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "288  Pfizer, Anti-DEI Group End Suit Over Diversity...   \n",
       "289  Ex-Goldman Banker Advances Some Pay Claims Aga...   \n",
       "290  ‘Greenhushing’ Emerges as Anti-ESG Pressures M...   \n",
       "291  Judge Halts CFPB Action After Alleged Plans to...   \n",
       "292  Ozy Media CEO Hit With $96 Million Restitution...   \n",
       "\n",
       "                                                  link  \\\n",
       "288  https://news.bloomberglaw.com/litigation/pfize...   \n",
       "289  https://news.bloomberglaw.com/litigation/ex-go...   \n",
       "290  https://news.bloomberglaw.com/litigation/green...   \n",
       "291  https://news.bloomberglaw.com/litigation/sensi...   \n",
       "292  https://news.bloomberglaw.com/litigation/ozy-m...   \n",
       "\n",
       "                       pubDate  \\\n",
       "288  2025-01-31 16:38:16-05:00   \n",
       "289  2025-02-07 09:56:06-05:00   \n",
       "290  2025-02-13 05:00:01-05:00   \n",
       "291  2025-02-14 18:05:53-05:00   \n",
       "292  2025-02-17 11:23:12-05:00   \n",
       "\n",
       "                                           description  \\\n",
       "288  Pfizer Inc. and a conservative group agreed to...   \n",
       "289  An investment banker who left Goldman Sachs & ...   \n",
       "290  The Trump administration's attacks on companie...   \n",
       "291  A federal judge on Friday ordered the Consumer...   \n",
       "292  Ozy Media chief executive Carlos Watson and hi...   \n",
       "\n",
       "                                                 topic  \n",
       "288  [preliminary injunctions, standing, mootness, ...  \n",
       "289  [investment professional compensation, resigna...  \n",
       "290  [environmental reporting, investment professio...  \n",
       "291  [bank supervision, consumer finance, mass layo...  \n",
       "292  [forfeiture, corporate officers, securities fr...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219125044.json\n",
      "Saved pickle to: ./data/scrape_result_20250219125044.pkl\n",
      "-------------- Credit Suisse  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n",
      "-- Current state: 2020-11-11-2020-12-11, record_count: 4, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 10, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 15, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 19, iter: 270\n",
      "-- Current state: 2022-07-04-2022-08-03, record_count: 29, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 40, iter: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2023-04-30-2023-05-30, record_count: 58, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 77, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 95, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 128, iter: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-12-20-2025-01-19, record_count: 152, iter: 305\n",
      "############## Result: 156 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Ex-Mozambique Minister Gets 8 1/2 Years in US ...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/ex-mo...</td>\n",
       "      <td>2025-01-17 17:33:15-05:00</td>\n",
       "      <td>A former Mozambique finance minister was sente...</td>\n",
       "      <td>[securities fraud, guarantee, wire fraud, sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Archegos CFO Gets Eight Years in Prison for De...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/arche...</td>\n",
       "      <td>2025-01-27 14:21:13-05:00</td>\n",
       "      <td>Former Archegos Capital Management CFO Patrick...</td>\n",
       "      <td>[witnesses, market manipulation, sentencing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Archegos Co-CEO Drops Bid for Hwang Money Afte...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/arche...</td>\n",
       "      <td>2025-01-28 14:58:20-05:00</td>\n",
       "      <td>Archegos Capital Management’s former co-chief ...</td>\n",
       "      <td>[corporate officers, witnesses, restitution, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Serta Lenders Seek Full Appeals Court Review o...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/serta...</td>\n",
       "      <td>2025-02-05 15:57:46-05:00</td>\n",
       "      <td>A group of lenders who participated in the con...</td>\n",
       "      <td>[confirmation of plan, indemnification, natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Credit Suisse Volatility Index Investors Get A...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/credi...</td>\n",
       "      <td>2025-02-12 15:01:34-05:00</td>\n",
       "      <td>UBS unit Credit Suisse Group AG faces an addit...</td>\n",
       "      <td>[market manipulation, class certification, lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "151  Ex-Mozambique Minister Gets 8 1/2 Years in US ...   \n",
       "152  Archegos CFO Gets Eight Years in Prison for De...   \n",
       "153  Archegos Co-CEO Drops Bid for Hwang Money Afte...   \n",
       "154  Serta Lenders Seek Full Appeals Court Review o...   \n",
       "155  Credit Suisse Volatility Index Investors Get A...   \n",
       "\n",
       "                                                  link  \\\n",
       "151  https://news.bloomberglaw.com/litigation/ex-mo...   \n",
       "152  https://news.bloomberglaw.com/litigation/arche...   \n",
       "153  https://news.bloomberglaw.com/litigation/arche...   \n",
       "154  https://news.bloomberglaw.com/litigation/serta...   \n",
       "155  https://news.bloomberglaw.com/litigation/credi...   \n",
       "\n",
       "                       pubDate  \\\n",
       "151  2025-01-17 17:33:15-05:00   \n",
       "152  2025-01-27 14:21:13-05:00   \n",
       "153  2025-01-28 14:58:20-05:00   \n",
       "154  2025-02-05 15:57:46-05:00   \n",
       "155  2025-02-12 15:01:34-05:00   \n",
       "\n",
       "                                           description  \\\n",
       "151  A former Mozambique finance minister was sente...   \n",
       "152  Former Archegos Capital Management CFO Patrick...   \n",
       "153  Archegos Capital Management’s former co-chief ...   \n",
       "154  A group of lenders who participated in the con...   \n",
       "155  UBS unit Credit Suisse Group AG faces an addit...   \n",
       "\n",
       "                                                 topic  \n",
       "151  [securities fraud, guarantee, wire fraud, sent...  \n",
       "152       [witnesses, market manipulation, sentencing]  \n",
       "153  [corporate officers, witnesses, restitution, c...  \n",
       "154  [confirmation of plan, indemnification, natura...  \n",
       "155  [market manipulation, class certification, lea...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219125836.json\n",
      "Saved pickle to: ./data/scrape_result_20250219125836.pkl\n",
      "-------------- Deutsche Bank  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n",
      "-- Current state: 2020-11-11-2020-12-11, record_count: 17, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 46, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 64, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 81, iter: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2022-07-04-2022-08-03, record_count: 105, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 121, iter: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2023-04-30-2023-05-30, record_count: 166, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 213, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 264, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 291, iter: 300\n",
      "-- Current state: 2024-12-20-2025-01-19, record_count: 304, iter: 305\n",
      "############## Result: 307 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Prudential Beats 401(k) Fund Class Action With...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/prude...</td>\n",
       "      <td>2024-12-20 09:45:15-05:00</td>\n",
       "      <td>Prudential Insurance Co. of America used an ap...</td>\n",
       "      <td>[summary judgment, class actions, mutual funds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Mexican Bank Units Must Face Bond-Manipulation...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/mexic...</td>\n",
       "      <td>2025-01-15 17:40:57-05:00</td>\n",
       "      <td>Mexican affiliates of big banks including Bank...</td>\n",
       "      <td>[dismissal, class actions, indemnification, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Deutsche Bank Again Can’t Recoup Billionaire’s...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/deuts...</td>\n",
       "      <td>2025-01-30 14:25:42-05:00</td>\n",
       "      <td>Deutsche Bank AG can't collect a $236 million ...</td>\n",
       "      <td>[civil fraud, state corporate regulation, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Investors Sue Drug Maker GSK Over Zantac Cance...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/inves...</td>\n",
       "      <td>2025-02-05 11:59:42-05:00</td>\n",
       "      <td>Global pharmaceutical company GSK Plc allegedl...</td>\n",
       "      <td>[settlements, class actions, securities violat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Unicredit Backs Down From UK Lawsuit After Rus...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/unicr...</td>\n",
       "      <td>2025-02-11 10:55:37-05:00</td>\n",
       "      <td>UniCredit SpA will stop pursuing a high stakes...</td>\n",
       "      <td>[multinational corporations, injunctions, inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "302  Prudential Beats 401(k) Fund Class Action With...   \n",
       "303  Mexican Bank Units Must Face Bond-Manipulation...   \n",
       "304  Deutsche Bank Again Can’t Recoup Billionaire’s...   \n",
       "305  Investors Sue Drug Maker GSK Over Zantac Cance...   \n",
       "306  Unicredit Backs Down From UK Lawsuit After Rus...   \n",
       "\n",
       "                                                  link  \\\n",
       "302  https://news.bloomberglaw.com/litigation/prude...   \n",
       "303  https://news.bloomberglaw.com/litigation/mexic...   \n",
       "304  https://news.bloomberglaw.com/litigation/deuts...   \n",
       "305  https://news.bloomberglaw.com/litigation/inves...   \n",
       "306  https://news.bloomberglaw.com/litigation/unicr...   \n",
       "\n",
       "                       pubDate  \\\n",
       "302  2024-12-20 09:45:15-05:00   \n",
       "303  2025-01-15 17:40:57-05:00   \n",
       "304  2025-01-30 14:25:42-05:00   \n",
       "305  2025-02-05 11:59:42-05:00   \n",
       "306  2025-02-11 10:55:37-05:00   \n",
       "\n",
       "                                           description  \\\n",
       "302  Prudential Insurance Co. of America used an ap...   \n",
       "303  Mexican affiliates of big banks including Bank...   \n",
       "304  Deutsche Bank AG can't collect a $236 million ...   \n",
       "305  Global pharmaceutical company GSK Plc allegedl...   \n",
       "306  UniCredit SpA will stop pursuing a high stakes...   \n",
       "\n",
       "                                                 topic  \n",
       "302  [summary judgment, class actions, mutual funds...  \n",
       "303  [dismissal, class actions, indemnification, ma...  \n",
       "304  [civil fraud, state corporate regulation, inte...  \n",
       "305  [settlements, class actions, securities violat...  \n",
       "306  [multinational corporations, injunctions, inte...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219130629.json\n",
      "Saved pickle to: ./data/scrape_result_20250219130629.pkl\n",
      "-------------- Barclays  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2020-11-11-2020-12-11, record_count: 10, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 19, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 30, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 40, iter: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2022-07-04-2022-08-03, record_count: 60, iter: 275\n",
      "-- Current state: 2022-12-01-2022-12-31, record_count: 77, iter: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2023-04-30-2023-05-30, record_count: 105, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 148, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 173, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 198, iter: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-12-20-2025-01-19, record_count: 218, iter: 305\n",
      "############## Result: 222 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Three Federal Tax Cases That Practitioners Mus...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/three...</td>\n",
       "      <td>2024-12-26 04:45:01-05:00</td>\n",
       "      <td>The most important federal tax cases in 2025 i...</td>\n",
       "      <td>[digital currency, jobs credits, federal tax, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Hearst Units Beat Ex-Worker’s Bid to Revive Va...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/hears...</td>\n",
       "      <td>2025-01-21 11:52:00-05:00</td>\n",
       "      <td>Two Hearst Corp. units reasonably relied on me...</td>\n",
       "      <td>[summary judgment, disabilities discrimination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>This Week in Chancery Court: Apollo, Fidelity,...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/this-...</td>\n",
       "      <td>2025-02-03 05:00:00-05:00</td>\n",
       "      <td>Apollo Global Management Inc. will ask the Del...</td>\n",
       "      <td>[dismissal, state corporate regulation, privat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Air Marshals Union Advances First Amendment Cl...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/air-m...</td>\n",
       "      <td>2025-02-05 10:19:11-05:00</td>\n",
       "      <td>A union that represents air marshals employed ...</td>\n",
       "      <td>[freedom of speech, dismissal, law enforcement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NY Counties Can Be Held Liable for Abuse of Fo...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/ny-co...</td>\n",
       "      <td>2025-02-18 12:38:01-05:00</td>\n",
       "      <td>Local governments in New York are responsible ...</td>\n",
       "      <td>[negligence, foster care, burden of proof, chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "217  Three Federal Tax Cases That Practitioners Mus...   \n",
       "218  Hearst Units Beat Ex-Worker’s Bid to Revive Va...   \n",
       "219  This Week in Chancery Court: Apollo, Fidelity,...   \n",
       "220  Air Marshals Union Advances First Amendment Cl...   \n",
       "221  NY Counties Can Be Held Liable for Abuse of Fo...   \n",
       "\n",
       "                                                  link  \\\n",
       "217  https://news.bloomberglaw.com/litigation/three...   \n",
       "218  https://news.bloomberglaw.com/litigation/hears...   \n",
       "219  https://news.bloomberglaw.com/litigation/this-...   \n",
       "220  https://news.bloomberglaw.com/litigation/air-m...   \n",
       "221  https://news.bloomberglaw.com/litigation/ny-co...   \n",
       "\n",
       "                       pubDate  \\\n",
       "217  2024-12-26 04:45:01-05:00   \n",
       "218  2025-01-21 11:52:00-05:00   \n",
       "219  2025-02-03 05:00:00-05:00   \n",
       "220  2025-02-05 10:19:11-05:00   \n",
       "221  2025-02-18 12:38:01-05:00   \n",
       "\n",
       "                                           description  \\\n",
       "217  The most important federal tax cases in 2025 i...   \n",
       "218  Two Hearst Corp. units reasonably relied on me...   \n",
       "219  Apollo Global Management Inc. will ask the Del...   \n",
       "220  A union that represents air marshals employed ...   \n",
       "221  Local governments in New York are responsible ...   \n",
       "\n",
       "                                                 topic  \n",
       "217  [digital currency, jobs credits, federal tax, ...  \n",
       "218  [summary judgment, disabilities discrimination...  \n",
       "219  [dismissal, state corporate regulation, privat...  \n",
       "220  [freedom of speech, dismissal, law enforcement...  \n",
       "221  [negligence, foster care, burden of proof, chi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219131422.json\n",
      "Saved pickle to: ./data/scrape_result_20250219131422.pkl\n",
      "-------------- Bank of America  --------------\n",
      "-- Current state: 2000-04-30-2000-05-30, record_count: 0, iter: 5\n",
      "-- Current state: 2000-09-27-2000-10-27, record_count: 0, iter: 10\n",
      "-- Current state: 2001-02-24-2001-03-26, record_count: 0, iter: 15\n",
      "-- Current state: 2001-07-24-2001-08-23, record_count: 0, iter: 20\n",
      "-- Current state: 2001-12-21-2002-01-20, record_count: 0, iter: 25\n",
      "-- Current state: 2002-05-20-2002-06-19, record_count: 0, iter: 30\n",
      "-- Current state: 2002-10-17-2002-11-16, record_count: 0, iter: 35\n",
      "-- Current state: 2003-03-16-2003-04-15, record_count: 0, iter: 40\n",
      "-- Current state: 2003-08-13-2003-09-12, record_count: 0, iter: 45\n",
      "-- Current state: 2004-01-10-2004-02-09, record_count: 0, iter: 50\n",
      "-- Current state: 2004-06-08-2004-07-08, record_count: 0, iter: 55\n",
      "-- Current state: 2004-11-05-2004-12-05, record_count: 0, iter: 60\n",
      "-- Current state: 2005-04-04-2005-05-04, record_count: 0, iter: 65\n",
      "-- Current state: 2005-09-01-2005-10-01, record_count: 0, iter: 70\n",
      "-- Current state: 2006-01-29-2006-02-28, record_count: 0, iter: 75\n",
      "-- Current state: 2006-06-28-2006-07-28, record_count: 0, iter: 80\n",
      "-- Current state: 2006-11-25-2006-12-25, record_count: 0, iter: 85\n",
      "-- Current state: 2007-04-24-2007-05-24, record_count: 0, iter: 90\n",
      "-- Current state: 2007-09-21-2007-10-21, record_count: 0, iter: 95\n",
      "-- Current state: 2008-02-18-2008-03-19, record_count: 0, iter: 100\n",
      "-- Current state: 2008-07-17-2008-08-16, record_count: 0, iter: 105\n",
      "-- Current state: 2008-12-14-2009-01-13, record_count: 0, iter: 110\n",
      "-- Current state: 2009-05-13-2009-06-12, record_count: 0, iter: 115\n",
      "-- Current state: 2009-10-10-2009-11-09, record_count: 0, iter: 120\n",
      "-- Current state: 2010-03-09-2010-04-08, record_count: 0, iter: 125\n",
      "-- Current state: 2010-08-06-2010-09-05, record_count: 0, iter: 130\n",
      "-- Current state: 2011-01-03-2011-02-02, record_count: 0, iter: 135\n",
      "-- Current state: 2011-06-02-2011-07-02, record_count: 0, iter: 140\n",
      "-- Current state: 2011-10-30-2011-11-29, record_count: 0, iter: 145\n",
      "-- Current state: 2012-03-28-2012-04-27, record_count: 0, iter: 150\n",
      "-- Current state: 2012-08-25-2012-09-24, record_count: 0, iter: 155\n",
      "-- Current state: 2013-01-22-2013-02-21, record_count: 0, iter: 160\n",
      "-- Current state: 2013-06-21-2013-07-21, record_count: 0, iter: 165\n",
      "-- Current state: 2013-11-18-2013-12-18, record_count: 0, iter: 170\n",
      "-- Current state: 2014-04-17-2014-05-17, record_count: 0, iter: 175\n",
      "-- Current state: 2014-09-14-2014-10-14, record_count: 0, iter: 180\n",
      "-- Current state: 2015-02-11-2015-03-13, record_count: 0, iter: 185\n",
      "-- Current state: 2015-07-11-2015-08-10, record_count: 0, iter: 190\n",
      "-- Current state: 2015-12-08-2016-01-07, record_count: 0, iter: 195\n",
      "-- Current state: 2016-05-06-2016-06-05, record_count: 0, iter: 200\n",
      "-- Current state: 2016-10-03-2016-11-02, record_count: 0, iter: 205\n",
      "-- Current state: 2017-03-02-2017-04-01, record_count: 0, iter: 210\n",
      "-- Current state: 2017-07-30-2017-08-29, record_count: 0, iter: 215\n",
      "-- Current state: 2017-12-27-2018-01-26, record_count: 0, iter: 220\n",
      "-- Current state: 2018-05-26-2018-06-25, record_count: 0, iter: 225\n",
      "-- Current state: 2018-10-23-2018-11-22, record_count: 0, iter: 230\n",
      "-- Current state: 2019-03-22-2019-04-21, record_count: 0, iter: 235\n",
      "-- Current state: 2019-08-19-2019-09-18, record_count: 0, iter: 240\n",
      "-- Current state: 2020-01-16-2020-02-15, record_count: 0, iter: 245\n",
      "-- Current state: 2020-06-14-2020-07-14, record_count: 0, iter: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2020-11-11-2020-12-11, record_count: 41, iter: 255\n",
      "-- Current state: 2021-04-10-2021-05-10, record_count: 90, iter: 260\n",
      "-- Current state: 2021-09-07-2021-10-07, record_count: 143, iter: 265\n",
      "-- Current state: 2022-02-04-2022-03-06, record_count: 193, iter: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2022-07-04-2022-08-03, record_count: 267, iter: 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2022-12-01-2022-12-31, record_count: 326, iter: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2023-04-30-2023-05-30, record_count: 421, iter: 285\n",
      "-- Current state: 2023-09-27-2023-10-27, record_count: 597, iter: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n",
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-02-24-2024-03-25, record_count: 771, iter: 295\n",
      "-- Current state: 2024-07-23-2024-08-22, record_count: 1021, iter: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gansh\\AppData\\Local\\Temp\\ipykernel_25860\\407789001.py:114: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['pubDate'] = pd.to_datetime(df['pubDate'], format='%a, %d %b %Y %H:%M:%S %z')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Current state: 2024-12-20-2025-01-19, record_count: 1193, iter: 305\n",
      "############## Result: 1242 records ##############\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Seven Cases to Watch as the Courts Weigh Trump...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/seven...</td>\n",
       "      <td>2025-02-15 08:00:22-05:00</td>\n",
       "      <td>President Donald Trump is now defending his wa...</td>\n",
       "      <td>[gender identity discrimination, unfair and de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>Willkie Removal in Bankruptcy Case Is Lesson i...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/willk...</td>\n",
       "      <td>2025-02-18 05:00:01-05:00</td>\n",
       "      <td>Willkie Farr &amp; Gallagher LLP's disqualificatio...</td>\n",
       "      <td>[attorney disqualification, leveraged buyout, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>Black Church Breaks New Legal Ground Taking Ov...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/black...</td>\n",
       "      <td>2025-02-18 05:05:02-05:00</td>\n",
       "      <td>A historic Black church unable to compel the f...</td>\n",
       "      <td>[default judgment, goodwill, freedom of speech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>What J&amp;J Is Trying to Achieve in Bankruptcy Co...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/what-...</td>\n",
       "      <td>2025-02-18 10:00:03-05:00</td>\n",
       "      <td>Johnson &amp; Johnson begins a two-week trial on F...</td>\n",
       "      <td>[settlements, personal use product safety, pha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>Merrill Lynch Ex-Advisers Look to Pause Deferr...</td>\n",
       "      <td>https://news.bloomberglaw.com/litigation/merri...</td>\n",
       "      <td>2025-02-18 13:52:33-05:00</td>\n",
       "      <td>Seven former financial advisers for Bank of Am...</td>\n",
       "      <td>[forfeiture, commission payments, mandatory ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "1237  Seven Cases to Watch as the Courts Weigh Trump...   \n",
       "1238  Willkie Removal in Bankruptcy Case Is Lesson i...   \n",
       "1239  Black Church Breaks New Legal Ground Taking Ov...   \n",
       "1240  What J&J Is Trying to Achieve in Bankruptcy Co...   \n",
       "1241  Merrill Lynch Ex-Advisers Look to Pause Deferr...   \n",
       "\n",
       "                                                   link  \\\n",
       "1237  https://news.bloomberglaw.com/litigation/seven...   \n",
       "1238  https://news.bloomberglaw.com/litigation/willk...   \n",
       "1239  https://news.bloomberglaw.com/litigation/black...   \n",
       "1240  https://news.bloomberglaw.com/litigation/what-...   \n",
       "1241  https://news.bloomberglaw.com/litigation/merri...   \n",
       "\n",
       "                        pubDate  \\\n",
       "1237  2025-02-15 08:00:22-05:00   \n",
       "1238  2025-02-18 05:00:01-05:00   \n",
       "1239  2025-02-18 05:05:02-05:00   \n",
       "1240  2025-02-18 10:00:03-05:00   \n",
       "1241  2025-02-18 13:52:33-05:00   \n",
       "\n",
       "                                            description  \\\n",
       "1237  President Donald Trump is now defending his wa...   \n",
       "1238  Willkie Farr & Gallagher LLP's disqualificatio...   \n",
       "1239  A historic Black church unable to compel the f...   \n",
       "1240  Johnson & Johnson begins a two-week trial on F...   \n",
       "1241  Seven former financial advisers for Bank of Am...   \n",
       "\n",
       "                                                  topic  \n",
       "1237  [gender identity discrimination, unfair and de...  \n",
       "1238  [attorney disqualification, leveraged buyout, ...  \n",
       "1239  [default judgment, goodwill, freedom of speech...  \n",
       "1240  [settlements, personal use product safety, pha...  \n",
       "1241  [forfeiture, commission payments, mandatory ar...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state to: ./data/scrape_state_20250219132236.json\n",
      "Saved pickle to: ./data/scrape_result_20250219132236.pkl\n"
     ]
    }
   ],
   "source": [
    "banks_arr = [\"UBS\", \"Citibank\", \"HSBC\", \"JPMorgan\", \"Goldman Sachs\", \"Credit Suisse\", \"Deutsche Bank\", \"Barclays\", \"Bank of America\"]\n",
    "for each_bank in banks_arr:\n",
    "    print(f\"-------------- {each_bank}  --------------\")\n",
    "    bloombergLawScraper.scrape(each_bank, start_time=date(2000,1,1), save_state=True, save_result=True, preview_result=True, scrape_period = 30, fetch_limit=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
